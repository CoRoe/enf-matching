{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ENF Extraction from Audio and Video Files\n",
        "\n",
        "Audio recordings may contain sum hum that is caused by the grid frequency interfering with the audio signal. If this noise is present in the audio signal depends on the recording equipment, the cabling, and so on.\n",
        "\n",
        "It is known that the grid frequency is not stricty 50 or 60 Hz but slightly fluctuates around the nominal value. These fluctuations are then also present in the audio audio recordings. If one matches the fluctuation of in the audio with the fluctuations of the grid frequency in the past that is is possible to chronolocate the audio recording, that is, determine the time when the recording was made.\n",
        "\n",
        "For this matching to work, one needs:\n",
        "- access to a database of historical network frequencies,\n",
        "- an audio clip containing a sufficient amount of network noise."
      ],
      "metadata": {
        "id": "SMttDsth7EKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Standard Modules"
      ],
      "metadata": {
        "id": "_qQnbnxpMfY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "\n",
        "# https://stackoverflow.com/questions/74157935/getting-the-file-name-of-downloaded-video-using-yt-dlp\n",
        "try:\n",
        "  import yp_dlp\n",
        "except:\n",
        "  !pip install -q yt-dlp\n",
        "  import yt_dlp\n",
        "\n",
        "!# Install the Python modules that are not yet present on Colab\n",
        "try:\n",
        "  import py7zr\n",
        "except:\n",
        "  !pip install -q py7zr\n",
        "  import py7zr\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "try:\n",
        "  import yp_dlp\n",
        "except:\n",
        "  !pip install -q yt-dlp\n",
        "  import yt_dlp\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import files\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "id": "4ZvaJo_NKuRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Custom ENF Modules from Github"
      ],
      "metadata": {
        "id": "JLyRo9YNNToQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5MtE_SPHy9H"
      },
      "outputs": [],
      "source": [
        "!# Clone the files on github to Colab so that they can be used\n",
        "![ -d enf-matching ] || git clone https://github.com/CoRoe/enf-matching.git\n",
        "!cd enf-matching; git pull\n",
        "\n",
        "# Add the path of the just cloned Python files to the Python path:\n",
        "if not '/content/enf-matching' in sys.path:\n",
        "    sys.path.insert(0, '/content/enf-matching')\n",
        "#print(sys.path)\n",
        "\n",
        "from enf import AudioClipEnf, GridEnf\n",
        "from enf import notch_filter, butter_bandpass_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Choose an Audio or Video Clip\n"
      ],
      "metadata": {
        "id": "UQ-PUUWIyC5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClipSelectionDlg():\n",
        "    \"\"\"Display a clip selection dialog, allowing to download or upload a file.\n",
        "    \"\"\"\n",
        "    def __init__(self, clip):\n",
        "      assert type(clip) == AudioClipEnf, \"Parameter clip must be of type AudioClipEnf\"\n",
        "      self.__clip = clip\n",
        "      self.__dlg_width = '800px'\n",
        "      self.__cell_width = '100px'\n",
        "\n",
        "    def __create_widgets(self):\n",
        "      self.__b_open = widgets.Button(description='Open file',\n",
        "                                     layout=widgets.Layout(width=self.__cell_width))\n",
        "      self.__b_open.on_click(self.__on_open)\n",
        "      self.__fn = widgets.Text(description=\"File\",\n",
        "                              layout=widgets.Layout(width='auto'))\n",
        "\n",
        "      self.__b_upload = widgets.Button(description='Upload file',\n",
        "                                     layout=widgets.Layout(width=self.__cell_width))\n",
        "      self.__b_upload.on_click(self.__on_upload)\n",
        "\n",
        "      self.__b_download = widgets.Button(description='Download file',\n",
        "                                     layout=widgets.Layout(width=self.__cell_width))\n",
        "      self.__b_download.on_click(self.__on_download)\n",
        "      self.__url = widgets.Text(description=\"URL\",\n",
        "                                layout=widgets.Layout(width='auto'))\n",
        "\n",
        "      self.__b_test = widgets.Button(description='Test file',\n",
        "                                     layout=widgets.Layout(width=self.__cell_width))\n",
        "      self.__b_test.on_click(self.__on_test)\n",
        "\n",
        "    def __create_layout(self):\n",
        "        grid = widgets.GridspecLayout(5, 8, layout=widgets.Layout(width=self.__dlg_width))\n",
        "        grid[0, 0:7] = widgets.Label(\"Please press one of the buttons\")\n",
        "        grid[1, 0] = self.__b_open\n",
        "        grid[1, 1:7] = self.__fn\n",
        "        grid[2, 0] = self.__b_upload\n",
        "        grid[3, 0] = self.__b_download\n",
        "        grid[3, 1:7] = self.__url\n",
        "        grid[4, 0] = self.__b_test\n",
        "        return grid\n",
        "\n",
        "    def __on_open(self, b):\n",
        "      print(\"Open button clicked\")\n",
        "      fn = self.__fn.value\n",
        "      if fn != '':\n",
        "        if self.__clip.loadAudioFile(self.__clip, fn):\n",
        "          print(f\"Loaded '{fn}' ok\")\n",
        "        else:\n",
        "          print(f\"Failed to load audio file '{fn}'\")\n",
        "      else:\n",
        "        print(\"No file selected\")\n",
        "      self.__clip\n",
        "\n",
        "    def __on_upload(self, b):\n",
        "      print(\"Click the 'browse' button to upload a file\")\n",
        "      uploaded = files.upload()\n",
        "      for fn in uploaded.keys():\n",
        "        print(f\"Loading {fn} ...\")\n",
        "        if self.__clip.loadAudioFile(self.__clip, fn):\n",
        "          print(f\"... ok\")\n",
        "        else:\n",
        "          print(f\"Failed to load audio file '{fn}'\")\n",
        "        break\n",
        "\n",
        "    def __on_download(self, b):\n",
        "      print(\"Download button clicked\")\n",
        "      url = self.__url.value\n",
        "      if url != '':\n",
        "        try:\n",
        "          with yt_dlp.YoutubeDL() as ydl:\n",
        "              info_dict = ydl.extract_info(url, download=True)\n",
        "              output_filename = ydl.prepare_filename(info_dict)\n",
        "              print(\"Downloaded file:\", output_filename)\n",
        "              if self.__clip.loadAudioFile(output_filename):\n",
        "                print(f\"Loaded '{output_filename}' ok\")\n",
        "              else:\n",
        "                print(f\"Failed to load audio file '{output_filename}'\")\n",
        "        except Exception as e:\n",
        "          print(\"Error:\", e)\n",
        "      else:\n",
        "        print(\"No URL entered\")\n",
        "\n",
        "    def __on_test(self, b):\n",
        "      if clip.loadAudioFile('/content/enf-matching/samplemedia/001.wav'):\n",
        "        print(f\"Loaded ok, sample rate {clip.sampleRate()}\")\n",
        "\n",
        "    def run(self):\n",
        "      \"\"\"Display the dialog and perform the action associated with the selected button.\n",
        "      \"\"\"\n",
        "      self.__create_widgets()\n",
        "      self.__dlg = self.__create_layout()\n",
        "      display(self.__dlg)\n",
        "\n",
        "\n",
        "clip = AudioClipEnf()\n",
        "dlg = ClipSelectionDlg(clip)\n",
        "dlg.run()"
      ],
      "metadata": {
        "id": "GK8azJPfa62e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Generate a Spectrogram\n",
        "\n",
        "A spectrogram visualises which frequencies are contained in a clip and how they vary over time. The hum component is usually very small will be visible only when frequencies outside the interesting range are suppressed. A bandfilter is used for that purpose.\n",
        "\n",
        "For further analysis, the parameters of the filter have to be choosen. You may play with the parameters to obtain better results.\n",
        "\n",
        "- **Grid frequency**; it is 50 Hz in most parts of the world and 60 Hz in the US.\n",
        "- **The harmonic**; in many cases instead of the base frequency some harmonic is present in the recording.\n",
        "- The **bandwidth of the bandpass**. The value should be set to the range in which grid frequency fluctuations are to be expected. A sensible value is 0.2 Hz.\n",
        "\n",
        "The spectrogram shows the frequency range around the chosen harmonic of the grid frequency. Brighter colours indicate a higher amplitude."
      ],
      "metadata": {
        "id": "9bIHkSREbeBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title For the next steps, some parameters have to be chosen.\n",
        "grid_freq = \"50\" # @param [\"50\",\"60\"]\n",
        "harmonic = \"2\" # @param [\"1\",\"2\", \"3\", \"4\"]\n",
        "freq_band = 0.2 # @param {\"type\":\"slider\",\"min\":0,\"max\":0.5,\"step\":0.01}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m9GMdyjK2yIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "butter_order = 20\n",
        "NFFT = 4096\n",
        "\n",
        "locut = int(harmonic) * (int(grid_freq) - freq_band)\n",
        "hicut = int(harmonic) * (int(grid_freq) + freq_band)\n",
        "ylim_lower = int(harmonic) * (int(grid_freq) - 5 * freq_band)\n",
        "ylim_upper = int(harmonic) * (int(grid_freq) + 5 * freq_band)\n",
        "\n",
        "filtered_data = butter_bandpass_filter(clip.data, locut, hicut,\n",
        "                                        clip.sampleRate(), butter_order)\n",
        "t = np.linspace(0, len(filtered_data)/clip.sampleRate(), len(filtered_data))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "Pxx, freqs, bins, im = ax.specgram(filtered_data, NFFT=NFFT, Fs=clip.sampleRate())\n",
        "# The `specgram` method returns 4 objects. They are:\n",
        "# - Pxx: the periodogram\n",
        "# - freqs: the frequency vector\n",
        "# - bins: the centers of the time bins\n",
        "# - im: the .image.AxesImage instance representing the data in the plot\n",
        "ax.set_ylim((ylim_lower, ylim_upper))\n",
        "ax.set_xlabel('Time (s)')\n",
        "ax.set_ylabel('Frequency (Hz)')\n",
        "ax.set_title('Spectrogram')"
      ],
      "metadata": {
        "id": "BKCCBfYmbmqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Extract ENF Fluctuations\n",
        "\n",
        "This step calculates the variation of the ENF signal over time."
      ],
      "metadata": {
        "id": "5HgMdfU00Ufg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip.makeEnf(int(grid_freq), 0.200, int(harmonic))\n",
        "t, f_enf = clip.getEnf()\n",
        "fig, (ax1) = plt.subplots(nrows=1, sharex=True)\n",
        "ax1.plot(t, f_enf/1000)\n",
        "ax1.set_xlabel('Time (s)')\n",
        "ax1.set_ylabel('ENF (Hz)')"
      ],
      "metadata": {
        "id": "KeV5y7Kh0ayR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Chronolocate the Clip\n",
        "\n",
        "There are several possibilities to chronolocate the clip:\n",
        "\n",
        "1.   Match against a database of historical ENF data. Unfortunately, there historical data are (so far?) available only for the UK.\n",
        "2.   Match against a self-recorded ENF values in a CSV file.\n",
        "3.   Match against a test WAV file.\n",
        "\n",
        "The latter two options use files in the `git` repository. The fields *month* and *year* below are not relevant for the test cases."
      ],
      "metadata": {
        "id": "vq64QUv21dWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Source of historical ENF data\n",
        "enf_hist_data_source = \"Test (CSV file)\" # @param [\"GB\",\"Test (WAV file)\", \"Test (CSV file)\"]\n",
        "month = \"1\" # @param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
        "year = 2024 # @param {\"type\":\"integer\"}\n",
        "enf_data_csv = \"/content/enf-matching/samplemedia/2024-08-19T15:26:02.csv\" # @param {\"type\":\"string\"}\n",
        "match_algo = \"Convolution\" # @param ['Convolution', 'Euclidian', 'Pearson']"
      ],
      "metadata": {
        "id": "uj1hK0wtH2Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The class GridEnf caches historical grid data in an SQL database.\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "  database_path = '/content/drive/MyDrive'\n",
        "else:\n",
        "  database_path = '/content'\n",
        "\n",
        "# Define a progress callback function\n",
        "def match_callback2(hint, progr):\n",
        "  pass\n",
        "\n",
        "def match_callback1(progr):\n",
        "  pass\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "ax[0].set_xlabel('Time (s)')\n",
        "ax[0].set_ylabel('ENF grid (Hz)')\n",
        "ax[1].set_xlabel('Time (s)')\n",
        "ax[1].set_ylabel('ENF clip (Hz)')\n",
        "ax[0].set_title('ENF Match')\n",
        "\n",
        "# Create an instance\n",
        "grid_data_loaded = False\n",
        "grid = GridEnf(database_path + '/hum.dp')\n",
        "if enf_hist_data_source == 'Test (WAV file)':\n",
        "  if grid.loadAudioFile('/content/enf-matching/samplemedia/71000_ref.wav'):\n",
        "    grid.makeEnf(int(grid_freq), freq_band, int(harmonic))\n",
        "    grid_data_loaded = True\n",
        "  else:\n",
        "    print(f\"Failed to load audio file\")\n",
        "elif enf_hist_data_source == 'Test (CSV file)':\n",
        "  grid.loadCSVFile(enf_data_csv)\n",
        "  enf = grid.enf\n",
        "  print(\"timestamp\", type(grid.getTimestamp()))\n",
        "  grid_data_loaded = True\n",
        "else:\n",
        "  grid.loadGridEnf(enf_hist_data_source, int(year), int(month), 1, match_callback2)\n",
        "  _, d = grid.getEnf()\n",
        "  if d is not None:\n",
        "    grid_data_loaded = True\n",
        "\n",
        "if grid_data_loaded:\n",
        "  print(\"Loaded\")\n",
        "  grid.matchClip(clip, match_algo, match_callback1)\n",
        "  t = grid.getMatchTimestamp()\n",
        "  clip.setTimestamp(t)\n",
        "\n",
        "  r = grid.getMatchRange()\n",
        "  print(\"Range:\", r)\n",
        "\n",
        "  ax[0].set_xlim(r)\n",
        "  ax[0].set_ylim(int(grid_freq) - freq_band, int(grid_freq) + freq_band)\n",
        "  ax[1].set_xlim(r)\n",
        "  ax[1].set_ylim(int(grid_freq) - freq_band, int(grid_freq) + freq_band)\n",
        "\n",
        "  t0, f_enf0 = grid.getEnf()\n",
        "  ax[0].plot(t0, f_enf0/1000)\n",
        "  t1, f_enf1 = clip.getEnf()\n",
        "  ax[1].plot(t1, f_enf1/1000)"
      ],
      "metadata": {
        "id": "-T3teA_SIaQ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}