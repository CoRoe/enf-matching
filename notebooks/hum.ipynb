{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ENF Extraction from Audio and Video Files\n",
        "\n",
        "Audio recordings may contain sum hum that is caused by the grid frequency interfering with the audio signal. If this noise is present in the audio signal depends on the recording equipment, the cabling, and so on.\n",
        "\n",
        "It is known that the grid frequency is not stricty 50 or 60 Hz but slightly fluctuates around the nominal value. These fluctuations are then also present in the audio audio recordings. If one matches the fluctuation of in the audio with the fluctuations of the grid frequency in the past that is is possible to chronolocate the audio recording, that is, determine the time when the recording was made.\n",
        "\n",
        "For this matching to work, one needs:\n",
        "- access to a database of historical network frequencies,\n",
        "- an audio clip containing a sufficient amount of network noise."
      ],
      "metadata": {
        "id": "SMttDsth7EKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Standard Modules"
      ],
      "metadata": {
        "id": "_qQnbnxpMfY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "\n",
        "# https://stackoverflow.com/questions/74157935/getting-the-file-name-of-downloaded-video-using-yt-dlp\n",
        "try:\n",
        "  import yp_dlp\n",
        "except:\n",
        "  !pip install -q yt-dlp\n",
        "  import yt_dlp\n",
        "\n",
        "!# Install the Python modules that are not yet present on Colab\n",
        "try:\n",
        "  import py7zr\n",
        "except:\n",
        "  !pip install -q py7zr\n",
        "  import py7zr\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import files\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "id": "4ZvaJo_NKuRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Custom ENF Modules from Github"
      ],
      "metadata": {
        "id": "JLyRo9YNNToQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5MtE_SPHy9H"
      },
      "outputs": [],
      "source": [
        "!# Clone the files on github to Colab so that they can be used\n",
        "![ -d enf-matching ] || git clone https://github.com/CoRoe/enf-matching.git\n",
        "!cd enf-matching; git pull\n",
        "\n",
        "# Add the path of the just cloned Python files to the Python path:\n",
        "if not '/content/enf-matching' in sys.path:\n",
        "    sys.path.insert(0, '/content/enf-matching')\n",
        "#print(sys.path)\n",
        "\n",
        "from enf import AudioClipEnf, GridEnf\n",
        "from enf import notch_filter, butter_bandpass_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Mount your Google Drive\n",
        "\n",
        "Mounting Google drive is sensible if you want to analyse media files you have stored there. Google will pop up a dialogue asking you for to authorise the mounting.**Text fett markieren**"
      ],
      "metadata": {
        "id": "_Brjs57oC5qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "  try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "  except:\n",
        "    print(\"Google Drive not mounted\")"
      ],
      "metadata": {
        "id": "j86fmT8aDUsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Choose an Audio or Video Clip\n",
        "\n",
        "The clip will be passed through `ffmpeg`. Ffmpeg will do two things:\n",
        "\n",
        "1.   Extract the audio track from a video file;\n",
        "2.   downsample it to 400 Hz and convert it to uncompressed PCM data.\n",
        "\n",
        "The downsampling reduces the storage requirements in the Python script.\n",
        "\n",
        "There are three ways to access a media file; use one of the following methods:\n",
        "\n",
        "1. **Internet video clip**: Paste the URL of the video page into the *url* field.\n",
        "2. **File on your computer**:\n",
        "3. **File on Colab**: Type the filename into the *media_file* field."
      ],
      "metadata": {
        "id": "UQ-PUUWIyC5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enf_data_source = \"Internet video clip\" # @param [\"File on Colab\",\"File on your computer\",\"Internet video clip\"]\n",
        "media_file = \"/content/enf-matching/samplemedia/001.wav\" # @param {\"type\":\"string\",\"placeholder\":\"Audio or video file\"}\n",
        "url = \"https://www.youtube.com/watch?v=4Un6B5ZnCUk\" # @param {\"type\":\"string\"}\n"
      ],
      "metadata": {
        "id": "L4cJsTw2AjRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if enf_data_source == 'File on your computer':\n",
        "  uploaded = files.upload()\n",
        "  if len(uploaded) > 0:\n",
        "    media_file = list(uploaded.keys())[0]\n",
        "    print(f\"Selected file: '{media_file}'\")\n",
        "elif enf_data_source == 'Internet video clip':\n",
        "  with yt_dlp.YoutubeDL() as ydl:\n",
        "      info_dict = ydl.extract_info(url, download=True)\n",
        "      output_filename = ydl.prepare_filename(info_dict)\n",
        "      media_file = output_filename\n",
        "      print(f\"Downloaded '{output_filename}'\")\n",
        "      media_file = output_filename\n"
      ],
      "metadata": {
        "id": "73vjxa2-_Xm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Load the Media File"
      ],
      "metadata": {
        "id": "UWxPsM-PCVX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip = AudioClipEnf()\n",
        "if clip.loadAudioFile(media_file):\n",
        "  print(f\"Loaded '{media_file}' ok, sample rate {clip.sampleRate()}\")\n",
        "else:\n",
        "  print(f\"Failed to load audio file '{media_file}'\")"
      ],
      "metadata": {
        "id": "1c7nPALQWlfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Generate a Spectrogram\n",
        "\n",
        "A spectrogram visualises which frequencies are contained in a clip and how they vary over time. The hum component is usually very small will be visible only when frequencies outside the interesting range are suppressed. A bandfilter is used for that purpose.\n",
        "\n",
        "For further analysis, the parameters of the filter have to be choosen. You may play with the parameters to obtain better results.\n",
        "\n",
        "- **Grid frequency**; it is 50 Hz in most parts of the world and 60 Hz in the US.\n",
        "- **The harmonic**; in many cases instead of the base frequency some harmonic is present in the recording.\n",
        "- The **bandwidth of the bandpass**. The value should be set to the range in which grid frequency fluctuations are to be expected. A sensible value is 0.2 Hz.\n",
        "\n",
        "The spectrogram shows the frequency range around the chosen harmonic of the grid frequency. Brighter colours indicate a higher amplitude."
      ],
      "metadata": {
        "id": "9bIHkSREbeBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title For the next steps, some parameters have to be chosen.\n",
        "grid_freq = \"50\" # @param [\"50\",\"60\"]\n",
        "harmonic = \"2\" # @param [\"1\",\"2\", \"3\", \"4\"]\n",
        "freq_band = 0.2 # @param {\"type\":\"slider\",\"min\":0,\"max\":0.5,\"step\":0.01}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m9GMdyjK2yIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "butter_order = 20\n",
        "NFFT = 4096\n",
        "\n",
        "locut = int(harmonic) * (int(grid_freq) - freq_band)\n",
        "hicut = int(harmonic) * (int(grid_freq) + freq_band)\n",
        "ylim_lower = int(harmonic) * (int(grid_freq) - 5 * freq_band)\n",
        "ylim_upper = int(harmonic) * (int(grid_freq) + 5 * freq_band)\n",
        "\n",
        "filtered_data = butter_bandpass_filter(clip.data, locut, hicut,\n",
        "                                        clip.sampleRate(), butter_order)\n",
        "t = np.linspace(0, len(filtered_data)/clip.sampleRate(), len(filtered_data))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "Pxx, freqs, bins, im = ax.specgram(filtered_data, NFFT=NFFT, Fs=clip.sampleRate())\n",
        "# The `specgram` method returns 4 objects. They are:\n",
        "# - Pxx: the periodogram\n",
        "# - freqs: the frequency vector\n",
        "# - bins: the centers of the time bins\n",
        "# - im: the .image.AxesImage instance representing the data in the plot\n",
        "ax.set_ylim((ylim_lower, ylim_upper))\n",
        "ax.set_xlabel('Time (s)')\n",
        "ax.set_ylabel('Frequency (Hz)')\n",
        "ax.set_title('Spectrogram')"
      ],
      "metadata": {
        "id": "BKCCBfYmbmqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Extract ENF Fluctuations\n",
        "\n",
        "This step calculates the variation of the ENF signal over time."
      ],
      "metadata": {
        "id": "5HgMdfU00Ufg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip.makeEnf(int(grid_freq), 0.200, int(harmonic))\n",
        "t, f_enf = clip.getEnf()\n",
        "fig, (ax1) = plt.subplots(nrows=1, sharex=True)\n",
        "ax1.plot(t, f_enf/1000)\n",
        "ax1.set_xlabel('Time (s)')\n",
        "ax1.set_ylabel('ENF (Hz)')"
      ],
      "metadata": {
        "id": "KeV5y7Kh0ayR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Chronolocate the Clip\n",
        "\n",
        "There are several possibilities to chronolocate the clip:\n",
        "\n",
        "1.   Match against a database of historical ENF data. Unfortunately, there historical data are (so far?) available only for the UK.\n",
        "2.   Match against a self-recorded ENF values in a CSV file.\n",
        "3.   Match against a test WAV file.\n",
        "\n",
        "The latter two options use files in the `git` repository. The fields *month* and *year* below are not relevant for the test cases."
      ],
      "metadata": {
        "id": "vq64QUv21dWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Source of historical ENF data\n",
        "enf_hist_data_source = \"Test (CSV file)\" # @param [\"GB\",\"Test (WAV file)\", \"Test (CSV file)\"]\n",
        "month = \"1\" # @param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
        "year = 2024 # @param {\"type\":\"integer\"}\n",
        "enf_data_csv = \"/content/enf-matching/samplemedia/2024-08-19T15:26:02.csv\" # @param {\"type\":\"string\"}\n",
        "match_algo = \"Convolution\" # @param ['Convolution', 'Euclidian', 'Pearson']"
      ],
      "metadata": {
        "id": "uj1hK0wtH2Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The class GridEnf caches historical grid data in an SQL database.\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "  database_path = '/content/drive/MyDrive'\n",
        "else:\n",
        "  database_path = '/content'\n",
        "\n",
        "# Define a progress callback function\n",
        "def match_callback2(hint, progr):\n",
        "  pass\n",
        "\n",
        "def match_callback1(progr):\n",
        "  pass\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "ax[0].set_xlabel('Time (s)')\n",
        "ax[0].set_ylabel('ENF grid (Hz)')\n",
        "ax[1].set_xlabel('Time (s)')\n",
        "ax[1].set_ylabel('ENF clip (Hz)')\n",
        "ax[0].set_title('ENF Match')\n",
        "\n",
        "# Create an instance\n",
        "grid_data_loaded = False\n",
        "grid = GridEnf(database_path + '/hum.dp')\n",
        "if enf_hist_data_source == 'Test (WAV file)':\n",
        "  if grid.loadAudioFile('/content/enf-matching/samplemedia/71000_ref.wav'):\n",
        "    grid.makeEnf(int(grid_freq), freq_band, int(harmonic))\n",
        "    grid_data_loaded = True\n",
        "  else:\n",
        "    print(f\"Failed to load audio file\")\n",
        "elif enf_hist_data_source == 'Test (CSV file)':\n",
        "  grid.loadCSVFile(enf_data_csv)\n",
        "  enf = grid.enf\n",
        "  print(\"timestamp\", type(grid.getTimestamp()))\n",
        "  grid_data_loaded = True\n",
        "else:\n",
        "  grid.loadGridEnf(enf_hist_data_source, int(year), int(month), 1, match_callback2)\n",
        "  _, d = grid.getEnf()\n",
        "  if d is not None:\n",
        "    grid_data_loaded = True\n",
        "\n",
        "if grid_data_loaded:\n",
        "  print(\"Loaded\")\n",
        "  grid.matchClip(clip, match_algo, match_callback1)\n",
        "  t = grid.getMatchTimestamp()\n",
        "  clip.setTimestamp(t)\n",
        "\n",
        "  r = grid.getMatchRange()\n",
        "  print(\"Range:\", r)\n",
        "\n",
        "  ax[0].set_xlim(r)\n",
        "  ax[0].set_ylim(int(grid_freq) - freq_band, int(grid_freq) + freq_band)\n",
        "  ax[1].set_xlim(r)\n",
        "  ax[1].set_ylim(int(grid_freq) - freq_band, int(grid_freq) + freq_band)\n",
        "\n",
        "  t0, f_enf0 = grid.getEnf()\n",
        "  ax[0].plot(t0, f_enf0/1000)\n",
        "  t1, f_enf1 = clip.getEnf()\n",
        "  ax[1].plot(t1, f_enf1/1000)"
      ],
      "metadata": {
        "id": "-T3teA_SIaQ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}